# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['embedding_explorer',
 'embedding_explorer.blueprints',
 'embedding_explorer.components',
 'embedding_explorer.plots',
 'embedding_explorer.prepare']

package_data = \
{'': ['*'], 'embedding_explorer': ['assets/*']}

install_requires = \
['dash-extensions>=0.1.10,<0.2.0',
 'dash-iconify>=0.1.2,<0.2.0',
 'dash-mantine-components>=0.11.1,<0.12.0',
 'dash>=2.7.1,<2.8.0',
 'neofuzz>=0.1.2',
 'numpy>=1.23.0',
 'pandas>=1.5.2,<1.6.0',
 'scikit-learn>=1.1.0,<1.2.0',
 'wordcloud>=1.8.2.2,<1.9.0.0']

setup_kwargs = {
    'name': 'embedding-explorer',
    'version': '0.4.0',
    'description': 'Tools for interactive visual inspection of semantic embeddings.',
    'long_description': '<img align="left" width="82" height="82" src="assets/logo.svg">\n\n# embedding-explorer\nTools for interactive visual exploration of semantic embeddings.\n\n## Installation\n\nInstall embedding-explorer from PyPI:\n\n```bash\npip install embedding-explorer\n```\n\n## Explorer\n\nembedding-explorer comes with a web application built for exploring semantic relations in a corpus with the help of embeddings.\nIn this section I will show a couple of examples of running the app with different embedding models and corpora.\n\n### Static Word Embeddings\nLet\'s say that you would like to explore semantic relations by investigating word embeddings generated with Word2Vec.\nYou can do this by passing the vocabulary of the model and the embedding matrix to embedding-explorer.\n\nFor this example I will use Gensim, which can be installed from PyPI:\n\n```bash\npip install gensim\n```\n\nWe will download GloVe Twitter 25 from gensim\'s repositories. \n```python\nfrom gensim import downloader\nfrom embedding_explorer import show_explorer\n\nmodel = downloader.load("glove-twitter-25")\nvocabulary = model.index_to_key\nembeddings = model.vectors\nshow_explorer(corpus=vocabulary, embeddings=embeddings)\n```\n\nThis will open a new browser window with the Explorer, where you can enter seed words and set the number of associations that you would\nlike to see on the screen.\n\n![Screenshot of the Explorer](assets/glove_screenshot.png)\n\n## Dynamic Embedding Models\n\nIf you want to explore relations in a corpus using let\'s say a sentence transformer, which creates contextually aware embeddings,\nyou can do so by specifying a scikit-learn compatible vectorizer model instead of passing along an embedding matrix.\n\nOne clear advantage here is that you can input arbitrary sequences as seeds instead of a predetermined set of texts.\n\nWe are going to use the package `embetter` for embedding documents.\n\n```bash\npip install embetter[sentence-trf]\n```\n\nI decided to examine four-grams in the 20newsgroups dataset. We will limit the number of four-grams to 4000 so we only see the most relevant ones.\n\n```python\nfrom embetter.text import SentenceEncoder\nfrom embedding_explorer import show_explorer\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ncorpus = fetch_20newsgroups(\n    remove=("headers", "footers", "quotes"),\n).data\n# We will use CountVectorizer for obtaining the possible n-grams\nfour_grams = (\n    CountVectorizer(\n        stop_words="english", ngram_range=(4, 4), max_features=4000\n    )\n    .fit(corpus)\n    .get_feature_names_out()\n)\n\nmodel = SentenceEncoder()\nshow_explorer(corpus=four_grams, vectorizer=model)\n```\n\n![Screenshot of the Explorer](assets/trf_screenshot.png)\n\n## Dashboard\n\nIf you have multiple models to examine the same corpus or multiple corpora, that you want to examine with the same model, then\nyou can create a dashboard containing all of these options, that users will be able to click on and that takes them to the appropriate explorer page.\n\nFor this we will have to assemble these options into a list of `Card` object, that contain the information about certain pages.\nCards have the same parameters as the `show_explorer` function.\n\nIn the following example I will set up two different sentence transformers with the same corpus from the previous example.\n\n```python\nfrom embetter.text import SentenceEncoder\nfrom embedding_explorer import show_dashboard, Card\n\ncards = [\n    Card("MiniLM", corpus=four_grams, vectorizer=SentenceEncoder("all-MiniLM-L12-v2")),\n    Card("MPNET", corpus=four_grams, vectorizer=SentenceEncoder("all-mpnet-base-v2")),\n]\nshow_dashboard(cards)\n```\n\n![Screenshot of the Dashboard](assets/dashboard_screenshot.png)\n\n## API Reference\n\n### `embedding_explorer.show_explorer(corpus, vectorizer=None, embeddings=None, port=8050, fuzzy_search=False)`\n\nVisually inspect word embedding model with the Explorer.\n\n#### Parameters\n\n| Parameter     | Type                        | Description                                                                                                                 | Default |\n|---------------|-----------------------------|-----------------------------------------------------------------------------------------------------------------------------|---------|\n| corpus        | _Iterable[str]_ | Texts you intend to search in with the semantic explorer.                                                                 | -       |\n| vectorizer    | _Optional[BaseEstimator]_     | Model to vectorize texts with. If not supplied, the model is assumed to be a static word embedding model, and the `embeddings` parameter has to be supplied. | `None`  |\n| embeddings    | _Optional[ndarray]_           | Embeddings of the texts in the corpus. If not supplied, embeddings will be calculated using the `vectorizer`.              | `None`  |\n| port          | _int_                         | Port for the app to run on.                                                                                                | `8050`  |\n| fuzzy_search  | _bool_                        | Specifies whether you want to enable fuzzy search in the vocabulary. Recommended for production use, but indexing takes time, resulting in longer startup time. | `False` |\n \n#### Returns\n| Type                   | Description                                                                                                         |\n|------------------------|---------------------------------------------------------------------------------------------------------------------|\n| _Thread_ or _None_       | If the app runs in a Jupyter notebook, work goes on in a background thread, and this thread is returned.           |\n\n### `embedding_explorer.show_dashboard(cards)`\n\nLaunch a dashboard with the given model cards.\n\n#### Parameters\n\n| Parameter | Type           | Description                                                                                                   | Default |\n|-----------|----------------|---------------------------------------------------------------------------------------------------------------|---------|\n| cards     | _list[Card]_   | Contains descriptions of model cards that should appear in the dashboard.                                     | -       |\n| port      | _int_            | Port for the app to run on.                                                                                   | 8050       |\n\n#### Returns\n| Type                   | Description                                                                                                         |\n|------------------------|---------------------------------------------------------------------------------------------------------------------|\n| _Thread_ or _None_       | If the app runs in a Jupyter notebook, work goes on in a background thread, and this thread is returned.           |\n\n### `class embedding_explorer.Card(corpus, vectorizer=None, embeddings=None, fuzzy_search=False)`\n\nContains information about an embedding model card that should be\ndisplayed on the dashboard.\n\n#### Parameters\n\n| Parameter     | Type                        | Description                                                                                                                 | Default |\n|---------------|-----------------------------|-----------------------------------------------------------------------------------------------------------------------------|---------|\n| corpus        | _Iterable[str]_ | Texts you intend to search in with the semantic explorer.                                                                 | -       |\n| vectorizer    | _Optional[BaseEstimator]_     | Model to vectorize texts with. If not supplied, the model is assumed to be a static word embedding model, and the `embeddings` parameter has to be supplied. | `None`  |\n| embeddings    | _Optional[ndarray]_           | Embeddings of the texts in the corpus. If not supplied, embeddings will be calculated using the `vectorizer`.              | `None`  |\n| fuzzy_search  | _bool_                        | Specifies whether you want to enable fuzzy search in the vocabulary. Recommended for production use, but indexing takes time, resulting in longer startup time. | `False` |\n',
    'author': 'MÃ¡rton Kardos',
    'author_email': 'power.up1163@gmail.com',
    'maintainer': 'None',
    'maintainer_email': 'None',
    'url': 'None',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'python_requires': '>=3.8.0',
}


setup(**setup_kwargs)
