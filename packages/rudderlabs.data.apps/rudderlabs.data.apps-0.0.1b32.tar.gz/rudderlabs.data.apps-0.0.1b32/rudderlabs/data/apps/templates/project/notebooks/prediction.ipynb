{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## README:\n",
    "\n",
    "App : **Sample Application**\n",
    "\n",
    "Stage : **Prediction**\n",
    "\n",
    "This is the sample notebook for loading data from s3 location \n",
    "\n",
    "Getting latest production model information from `model_registry_table` mentioned in `credentials.yaml` configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import joblib\n",
    "import logging\n",
    "import tempfile\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "#Rudderlab data utilities imports\n",
    "from rudderlabs.data.apps.log import setup_file_logger\n",
    "from rudderlabs.data.apps.config import read_yaml\n",
    "from rudderlabs.data.apps.utils import get_latest_folder\n",
    "from rudderlabs.data.apps.aws.s3 import upload_file_to_s3, download_s3_directory, parse_s3_path, get_s3_resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e3000",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters cell for papermill. These values can get overridden by parameters passed by papermill\n",
    "job_id = None\n",
    "local_input_path = None\n",
    "local_output_path = None\n",
    "code_path = \"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not job_id:\n",
    "    job_id = get_latest_folder(\"../data\").split(\"/\")[-1]\n",
    "    print(f\"Data prep run id is not given. Taking the latest run id: {job_id}\")\n",
    "\n",
    "job_id = str(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if local_output_path is None:\n",
    "    local_output_path = f\"../data/{job_id}/prediction\"\n",
    "    if not os.path.exists(local_output_path):\n",
    "        os.makedirs(local_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e33bdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Local imports\n",
    "sys.path.append(code_path)\n",
    "from model_loader import ModelLoader\n",
    "from data_loader import DataIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e35075f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "# All the required constants are defined here\n",
    "IMAGE_FORMAT = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7983552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logging setup\n",
    "try:\n",
    "    log_file_path = os.path.join(local_output_path, \"logs\", \"prediction.log\")\n",
    "    logging = setup_file_logger(log_file_path)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "logging.info(\"\\n\\n\\t\\tSTARTING PREDICTION\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6405ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurations\n",
    "notebook_config = read_yaml(os.path.join(code_path, \"config/data_prep.yaml\"))\n",
    "print(\"Notebook config:\")\n",
    "pprint(notebook_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb663a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "creds_config = read_yaml(os.path.join(code_path, \"credentials.yaml\"))\n",
    "print(\"Credentials config:\")\n",
    "pprint(creds_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_features = notebook_config[\"data\"][\"ignore_features\"]\n",
    "label_column = notebook_config[\"data\"][\"label_column\"]\n",
    "entity_column = notebook_config[\"data\"][\"entity_column\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading model from model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loader = ModelLoader(creds_config)\n",
    "model_data = model_loader.get_latest_model(model_type=\"staging\")\n",
    "\n",
    "print(\"Model data:\")\n",
    "pprint(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder = tempfile.mkdtemp()\n",
    "print(f\"Downloading model data to temporary location {temp_folder}\")\n",
    "\n",
    "s3_bucket, s3_prefix = parse_s3_path(model_data[\"model_files_location\"])\n",
    "s3_resource = get_s3_resource(creds_config)\n",
    "\n",
    "download_s3_directory(s3_resource, s3_bucket, s3_prefix, temp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = None\n",
    "with open(os.path.join(temp_folder, \"data_pipeline.pkl\"), \"rb\") as f:\n",
    "    preprocessor = pickle.load(f)\n",
    "\n",
    "model = joblib.load(os.path.join(temp_folder, \"saved_model.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading sample data\")\n",
    "data_io = DataIO({}, creds_config)\n",
    "input_data = data_io.get_data_for_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignoring features\n",
    "#Select valid columns to ignore from the feature table\n",
    "ignore_features = [ col for col in ignore_features if col in input_data.columns ]\n",
    "print(f\"Ignoring features {ignore_features}\")\n",
    "logging.info(f\"Ignoring features {ignore_features}\")\n",
    "data = input_data.drop(columns=ignore_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running preprocessing pipeline\")\n",
    "data = preprocessor.transform(data.drop(columns=[label_column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicting\")\n",
    "prediction_scores = model.predict_proba(data)\n",
    "\n",
    "display_output = pd.concat([ input_data.reset_index(), pd.Series(prediction_scores[:,1], name=\"prediction_score\")], axis=1)\n",
    "\n",
    "\n",
    "cols = [entity_column, label_column, \"prediction_score\"]\n",
    "for col in display_output.columns:\n",
    "    if col not in [\"user\",\"prediction_score\", label_column]:\n",
    "        cols.append(col)\n",
    "        \n",
    "display_output[cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the sample datapoints with their actual label, prediction, and their features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8377c421-06c3-4d04-a34b-6cb63372ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.title(\"Prediction scores distribution of converted and non converted users\")\n",
    "plt.xlim([0,1])\n",
    "sns.kdeplot(\"prediction_score\", data=display_output, hue=label_column, common_norm=False);\n",
    "plt.savefig(os.path.join(local_output_path, \"prediction_scores_dist.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d402919-a1ee-43da-9909-d5153eb69b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "actual = input_data[label_column]\n",
    "data_predictions = pd.concat([actual.reset_index(drop = True), pd.Series(prediction_scores[:,1])], axis = 1)\n",
    "data_predictions.columns = ['actual', 'prob_c']\n",
    "\n",
    "data_predictions['deciles'] = pd.qcut(data_predictions[\"prob_c\"].rank(method='first'), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77913317-c532-4044-903a-46ec00455b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare actual conversion in each decile\n",
    "# pandas groupby is a useful function for \n",
    "lift = data_predictions.groupby(data_predictions[\"deciles\"])['actual'].agg([\"sum\", \"count\"]).reset_index()\n",
    "\n",
    "# existing conversion rate in the data\n",
    "x = sum(lift['sum'])/sum(lift['count'])\n",
    "\n",
    "# calculate conversion probs\n",
    "lift['prob_con'] = lift['sum']/lift['count']\n",
    "\n",
    "# get cumulative counts and probabilities \n",
    "lift['sum_c'] = lift['sum'].iloc[::-1].cumsum()\n",
    "lift['prop_c'] = lift['sum_c']/np.sum(lift['sum'])\n",
    "\n",
    "# old model - 40% conversion by random selection\n",
    "lift['old'] = lift['count']*x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1b9621-2051-42f0-a0d9-57796781913e",
   "metadata": {},
   "source": [
    "## Lift plot\n",
    "\n",
    "Here we compare the cumulative gains in converted customers we get from our model compared to what we get by calling leads randomly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5e1595-253d-44a7-9aae-8b25ee9fa731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lift plot\n",
    "plt.figure(figsize=(16,5))\n",
    "ax = plt.gca()\n",
    "\n",
    "d = np.linspace(0.1,1,10).round(1)\n",
    "\n",
    "ax.plot(lift.index, lift['prop_c'].iloc[::-1]*100, marker='o')\n",
    "ax.plot(lift.index, d*100, color = 'red', marker='o')\n",
    "plt.legend([\"Using lead score\", \"Random\"])\n",
    "plt.xticks(lift.index, labels=d*100)\n",
    "plt.title(\"Lift Chart\")\n",
    "plt.xlabel(\"% of Leads\")\n",
    "plt.ylabel(\"% of Conversions\")\n",
    "plt.grid(True)\n",
    "try:\n",
    "    plt.savefig(os.path.join(local_output_path, \"lift.png\"))\n",
    "except:\n",
    "    pass\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa795b79-79a5-4017-9936-58447a9d6798",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Copying the predction outputs as csv to location:\\n\\t{local_output_path}\")\n",
    "\n",
    "display_output.to_csv(os.path.join(local_output_path,\"predictions.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f76794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd4e756-5184-4c03-9402-252129a587c6",
   "metadata": {},
   "source": [
    "### Writing the predictions back to warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56063554-929b-4114-87e1-c8c19803cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_data = display_output[entity_column]\n",
    "output_data = display_output[[entity_column, \"prediction_score\"]]\n",
    "output_data[\"updated_at\"] = datetime.datetime.now()\n",
    "\n",
    "output_data.columns = [ col.lower().replace(\" \", \"_\") for col in output_data.columns ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d228c0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Output data length : {len(output_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3362afd5-0b46-44d0-b5a9-55fd76256393",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_io = DataIO(notebook_config, creds_config)\n",
    "\n",
    "data_io.write_to_wh_table(\n",
    "    df = output_data, \n",
    "    table_name = creds_config[\"data_warehouse\"][\"prediction_store_table\"], \n",
    "    schema = creds_config[\"data_warehouse\"][\"schema\"], \n",
    "    if_exists=\"append\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f6174d-26a7-4671-8755-d9cccbc15492",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The output data is stored in the warehouse table: {creds_config[\"data_warehouse\"][\"prediction_store_table\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cell to hide code while converting to a html page\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "$('div.input').hide();\n",
    "</script>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('rlabs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb9dda7c9d815e1cdc337d7fe8d5832923daae4c84b0a4e15a32dd1f30943ba5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
