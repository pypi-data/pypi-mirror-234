{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## README:\n",
    "\n",
    "App : **Sample Application**\n",
    "\n",
    "Stage : **Validation**\n",
    "\n",
    "This is the sample notebook for loading golden dataset from s3 location and evaluating staging model and production model\n",
    "\n",
    "Based on acceptance criteria staging model will be moved to production.\n",
    "\n",
    "If there is no production model, latest staging model will be moved to production without any acceptance criteria.\n",
    "\n",
    "Stagging and production models information can be queried from `model_registry_table` mentioned in `credentials.yaml` configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import joblib\n",
    "import logging\n",
    "import tempfile\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "#Rudderlab data utilities imports\n",
    "from rudderlabs.data.apps.log import setup_file_logger\n",
    "from rudderlabs.data.apps.config import read_yaml\n",
    "from rudderlabs.data.apps.utils import get_latest_folder\n",
    "from rudderlabs.data.apps.aws.s3 import upload_file_to_s3, download_s3_directory, parse_s3_path, get_s3_resource, copy_s3_to_s3\n",
    "\n",
    "from sklearn.metrics import get_scorer\n",
    "\n",
    "pd.options.display.max_columns=None\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e3000",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters cell for papermill. These values can get overridden by parameters passed by papermill\n",
    "job_id = None\n",
    "local_input_path = None\n",
    "local_output_path = None\n",
    "validation_output_path = None\n",
    "code_path = \"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not job_id:\n",
    "    job_id = get_latest_folder(\"../data\").split(\"/\")[-1]\n",
    "    print(f\"Data prep run id is not given. Taking the latest run id: {job_id}\")\n",
    "\n",
    "job_id = str(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if local_output_path is None:\n",
    "    local_output_path = f\"../data/{job_id}/validation\"\n",
    "    if not os.path.exists(local_output_path):\n",
    "        os.makedirs(local_output_path)\n",
    "\n",
    "if validation_output_path is None:\n",
    "    validation_output_path = local_output_path\n",
    "else:\n",
    "    validation_output_path = validation_output_path.replace(\"<job_id>\", job_id)\n",
    "print(f\"Validation output path: {validation_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e33bdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Local imports\n",
    "sys.path.append(code_path)\n",
    "from model_loader import ModelLoader\n",
    "from data_loader import DataIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e35075f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "# All the required constants are defined here\n",
    "IMAGE_FORMAT = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7983552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logging setup\n",
    "try:\n",
    "    log_file_path = os.path.join(local_output_path, \"logs\", \"validation.log\")\n",
    "    logging = setup_file_logger(log_file_path)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "logging.info(\"\\n\\n\\t\\tSTARTING PREDICTION\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6405ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurations\n",
    "data_prep_config = read_yaml(os.path.join(code_path, \"config/data_prep.yaml\"))\n",
    "print(\"Data Preparation Configurations:\")\n",
    "pprint(data_prep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurations\n",
    "notebook_config = read_yaml(os.path.join(code_path, \"config/validation.yaml\"))\n",
    "print(\"Validation Configurations:\")\n",
    "pprint(notebook_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb663a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "creds_config = read_yaml(os.path.join(code_path, \"credentials.yaml\"))\n",
    "print(\"Credentials config:\")\n",
    "pprint(creds_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_features = data_prep_config[\"data\"][\"ignore_features\"]\n",
    "label_column = data_prep_config[\"data\"][\"label_column\"]\n",
    "entity_column = data_prep_config[\"data\"][\"entity_column\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get staging and production models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loader = ModelLoader(creds_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stagging model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Getting latest model for job_id: {job_id}\")\n",
    "staging_model_data = model_loader.get_latest_model(model_type=\"staging\", job_id=job_id)\n",
    "\n",
    "print(\"Stagging model data:\")\n",
    "pprint(staging_model_data)\n",
    "\n",
    "print(\"Downloading staging model\")\n",
    "stagginmodel_path = model_loader.download_model_files_to_temp(staging_model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Production model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting latest production model\")\n",
    "prod_model_data = model_loader.get_latest_model(model_type=\"production\")\n",
    "\n",
    "print(\"Latest production model data:\")\n",
    "pprint(prod_model_data)\n",
    "\n",
    "print(\"Downloading production model\")\n",
    "prod_model_path = model_loader.download_model_files_to_temp(prod_model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing golden dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using same preprocessing pipeline for evaluating data on both staging and production models. In case the preprocessing pipeline and configuration used for `data preparation step` is different for staging and production model. User needs to do following things\n",
    "* Upload configuration files to s3 location where model files get stored\n",
    "* Use those configuration and preprocessing pipeline for respective model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_io = DataIO(notebook_config, creds_config)\n",
    "golden_data_s3_location = creds_config[\"aws\"][\"golden_dataset_s3_location\"]\n",
    "golden_data = data_io.get_data_from_s3(golden_data_s3_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples from gloden dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "golden_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_preprocessor = None\n",
    "with open(os.path.join(stagginmodel_path, \"data_pipeline.pkl\"), \"rb\") as f:\n",
    "    stage_preprocessor = pickle.load(f)\n",
    "\n",
    "stage_model = joblib.load(os.path.join(stagginmodel_path, \"saved_model.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignoring features\n",
    "#Select valid columns to ignore from the feature table\n",
    "ignore_features = [ col for col in ignore_features if col in golden_data.columns ]\n",
    "print(f\"Ignoring features {ignore_features}\")\n",
    "logging.info(f\"Ignoring features {ignore_features}\")\n",
    "data = golden_data.drop(columns=ignore_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running preprocessing pipeline\")\n",
    "input_data = stage_preprocessor.transform(data.drop(columns=[label_column]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = notebook_config[\"model\"][\"evaluation_metrics\"]\n",
    "print(f\"Metrics to calculate: {metric_names}\")\n",
    "\n",
    "acceptance_metric_name = notebook_config[\"model\"][\"acceptance_criteria\"][\"metric_name\"]\n",
    "acceptance_metric_threshold = notebook_config[\"model\"][\"acceptance_criteria\"][\"threshold\"]\n",
    "\n",
    "if acceptance_metric_name not in metric_names:\n",
    "    metric_names.append(acceptance_metric_name)\n",
    "\n",
    "print(f\"Acceptance metric: {acceptance_metric_name}\")\n",
    "print(f\"Acceptance metric threshold: {acceptance_metric_threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating metrics\n",
    "def get_metrics(model, X_data, Y_data, threshold):\n",
    "    predictions = model.predict_proba(X_data)[:, 1]\n",
    "    metrics = {}\n",
    "    for metric in metric_names:\n",
    "        try:\n",
    "            scorer = get_scorer(metric)\n",
    "            metrics[metric] = scorer._score_func(Y_data, np.where(predictions >  threshold, 1, 0))\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            pass\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staging_model_threshold = staging_model_data[\"threshold\"]\n",
    "print(f\"Calculating metrics for staging model with threshold {staging_model_threshold}\")\n",
    "staging_metrics = get_metrics(stage_model, input_data, data[label_column], staging_model_threshold)\n",
    "print(f\"Stagging model metrics: {staging_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_metrics = {}\n",
    "\n",
    "if prod_model_path is not None:\n",
    "    prod_model_threshold = prod_model_data[\"threshold\"]\n",
    "    print(f\"Calculating metrics for production model with threshold {prod_model_threshold}\")\n",
    "    prod_model = joblib.load(os.path.join(prod_model_path, \"saved_model.pkl\"))\n",
    "    prod_metrics = get_metrics(prod_model, input_data, data[label_column], prod_model_threshold)\n",
    "else:\n",
    "    print(\"No production model found\")\n",
    "    print(\"Copying staging model metrics to production metrics, so that the acceptance criteria can be checked\")\n",
    "    prod_metrics = staging_metrics\n",
    "\n",
    "print(f\"Production model metrics: {prod_metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Stagging and Production models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing metrics\n",
    "print(f\"Comparing metrics for staging model and production model\")\n",
    "accepted = False\n",
    "\n",
    "try:\n",
    "    if staging_metrics[acceptance_metric_name] > acceptance_metric_threshold * prod_metrics[acceptance_metric_name]:\n",
    "        print(f\"Stagging model is accepted\")\n",
    "        logging.info(f\"Stagging model is accepted\")\n",
    "        accepted = True\n",
    "        new_prod_data = staging_model_data.copy()\n",
    "        #Remove ID\n",
    "        if \"id\" in new_prod_data:\n",
    "            new_prod_data.pop(\"id\")\n",
    "\n",
    "        new_prod_data[\"timestamp\"] = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        new_prod_data[\"metrics\"] = json.dumps(staging_metrics)\n",
    "        new_prod_data[\"model_type\"] = \"production\"\n",
    "\n",
    "        s3_resource = get_s3_resource(creds_config)\n",
    "        staging_model_s3_location = staging_model_data[\"model_files_location\"]\n",
    "        \n",
    "        production_model_s3_location = staging_model_s3_location.replace(\n",
    "            creds_config[\"aws\"][\"staging_models_s3_prefix\"],\n",
    "            creds_config[\"aws\"][\"production_models_s3_prefix\"]\n",
    "        )\n",
    "\n",
    "        new_prod_data[\"model_files_location\"] = production_model_s3_location\n",
    "\n",
    "        print(f\"Copying staging model files from {staging_model_s3_location} to production model location: {production_model_s3_location}\")\n",
    "\n",
    "        copy_s3_to_s3(\n",
    "            s3_resource = s3_resource,\n",
    "            source = staging_model_s3_location,\n",
    "            destination = production_model_s3_location,\n",
    "            delete_source = False\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        print(f\"Stagging model is rejected\")\n",
    "        logging.info(f\"Stagging model is rejected\")\n",
    "except Exception as e:\n",
    "    print(str(e))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_registry_table = creds_config[\"data_warehouse\"][\"model_registry_table\"]\n",
    "\n",
    "def update_model_registry(data_io, table_data):\n",
    "    payload = pd.DataFrame(table_data, index=[0])\n",
    "\n",
    "    data_io.write_to_wh_table(\n",
    "        df = payload,\n",
    "        table_name = model_registry_table,\n",
    "        schema = creds_config[\"data_warehouse\"][\"schema\"],\n",
    "        if_exists = \"append\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staging_model_data[\"evaluation_files_location\"] = validation_output_path\n",
    "staging_model_data[\"metrics\"] = json.dumps(staging_metrics)\n",
    "\n",
    "data_io = DataIO(notebook_config, creds_config)\n",
    "print(f\"Updating model registry table {model_registry_table}\")\n",
    "\n",
    "print(\"Updating staging model data\")\n",
    "pprint(staging_model_data)\n",
    "\n",
    "id_value = staging_model_data.pop(\"id\")\n",
    "data_io.update_wh_table(\n",
    "    data = staging_model_data,\n",
    "    table_name = model_registry_table,\n",
    "    schema = creds_config[\"data_warehouse\"][\"schema\"],\n",
    "    where = f\"id = '{id_value}'\"\n",
    ")\n",
    "\n",
    "if accepted:\n",
    "    print(\"Updating production model data\")\n",
    "    pprint(new_prod_data)\n",
    "    update_model_registry(data_io, new_prod_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('rlabs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb9dda7c9d815e1cdc337d7fe8d5832923daae4c84b0a4e15a32dd1f30943ba5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
