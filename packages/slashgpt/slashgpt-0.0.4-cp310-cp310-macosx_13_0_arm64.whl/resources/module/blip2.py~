

from transformers import AutoProcessor, Blip2ForConditionalGeneration
import torch

import requests
from PIL import Image

url = 'https://firebasestorage.googleapis.com/v0/b/ownplate-jp.appspot.com/o/images%2Frestaurants%2FwikCeW5ObGDjmzQaOfHj%2Fmenus%2FklBxP0xUqy6HZO5KNEiN%2Fitem.jpg?alt=media&token=01b10976-5d52-49ec-b590-70817e185ba4'
image = Image.open(requests.get(url, stream=True).raw).convert('RGB')  
# display(image.resize((596, 437)))


processor = AutoProcessor.from_pretrained("Salesforce/blip2-opt-2.7b")
model = Blip2ForConditionalGeneration.from_pretrained("Salesforce/blip2-opt-2.7b")

device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)

inputs = processor(image, return_tensors="pt").to(device)

generated_ids = model.generate(**inputs, max_new_tokens=20)
generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()
print(generated_text)


