{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79036a8c",
   "metadata": {
    "tags": [],
    "id": "79036a8c"
   },
   "source": [
    "# LLM Tracing\n",
    "\n",
    "With the Parea SDK, you can gain visibility into **any LLM application**. Together with the web application, Parea speeds up your debugging, evaluating, and monitoring workflows.\n",
    "Parea is also framework and provider-agnostic. Parea traces your prompts and chains, whether deployed from Parea or within your codebase.\n",
    "\n",
    "We will create a simple chat app and instrument logging with Parea. We will also add tags and other metadata to enrich our traces. The chat app uses three 'chained' components to generate a text argument on a provided subject:\n",
    "\n",
    "1. An argument generation function\n",
    "2. Critique function\n",
    "3. Refine function\n",
    "\n",
    "Each function will call an LLM provider; in our case, we'll use OpenAI, but you could quickly call Anthropic or Azure. Parea's dashboard shows how the LLM calls are organized for further analysis and investigation.\n",
    "\n",
    "![DashboardDetailedView](img/dashboard_detailed_view.png)\n",
    "\n",
    "Let's go!\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "First, install the parea-ai SDK package. If you have an account with Parea, your LLM API Keys will be automatically used, so you won't need to redefine them here.\n",
    "All you need is your Parea API key. Follow the instructions in the [docs](https://docs.parea.ai/api-reference/authentication) to get your api keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5615479e",
   "metadata": {
    "id": "5615479e",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# %pip install -U parea-ai > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ebe2c0",
   "metadata": {
    "id": "06ebe2c0"
   },
   "source": [
    "Next, configure the API Key in the environment to log traces to your account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f665dbcd",
   "metadata": {
    "id": "f665dbcd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3713f0ab-b90a-4751-ca0a-6d28ceebb385",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PAREA_API_KEY\"] = \"<your-api-key>\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using the SDK\n",
    "\n",
    "Next, define your chat application. Using the trace decorator will automatically generate a trace_id for each of your LLM calls. The decorated functions inputs, name, and other information are recorded and visible on Parea's dashboard. This is all done on a background thread to avoid blocking your app's execution.\n",
    "\n",
    "We've created three prompts on Parea and have deployed them. Learn how to deploy a prompt [here](https://docs.parea.ai/deployments/deployments).\n",
    "\n",
    "![Deployed_Prompts](img/deployed_prompts.png)\n",
    "\n",
    "Now we only need the deployment id for each prompt to get started. You can also do this without a deployed prompt; we'll revisit this example in another walkthrough."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f23ca7811eea9dd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba8c359",
   "metadata": {
    "tags": [],
    "id": "4ba8c359",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from parea.utils.trace_utils import trace\n",
    "from datetime import datetime\n",
    "\n",
    "from parea import Parea\n",
    "from parea.schemas.models import Completion\n",
    "\n",
    "p = Parea(api_key=os.getenv(\"PAREA_API_KEY\"))\n",
    "\n",
    "\n",
    "def argument_generator(query: str, additional_description: str = \"\") -> str:\n",
    "    return p.completion(\n",
    "        Completion(\n",
    "            deployment_id=\"p-XOh3kp8B0nIE82WgioPnr\",\n",
    "            llm_inputs={\n",
    "                \"additional_description\": additional_description,\n",
    "                \"date\": f\"{datetime.now()}\",\n",
    "                \"query\": query,\n",
    "            },\n",
    "        )\n",
    "    ).content\n",
    "\n",
    "\n",
    "def critic(argument: str) -> str:\n",
    "    return p.completion(\n",
    "        Completion(\n",
    "            deployment_id=\"p-PSOwRyIPaQRq4xQW3MbpV\",\n",
    "            llm_inputs={\"argument\": argument},\n",
    "        )\n",
    "    ).content\n",
    "\n",
    "\n",
    "def refiner(query: str, additional_description: str, argument: str, criticism: str) -> str:\n",
    "    return p.completion(\n",
    "        Completion(\n",
    "            deployment_id=\"p-bJ3-UKh9-ixapZafaRBsj\",\n",
    "            llm_inputs={\n",
    "                \"additional_description\": additional_description,\n",
    "                \"date\": f\"{datetime.now()}\",\n",
    "                \"query\": query,\n",
    "                \"argument\": argument,\n",
    "                \"criticism\": criticism,\n",
    "            },\n",
    "        )\n",
    "    ).content\n",
    "\n",
    "\n",
    "@trace\n",
    "def argument_chain(query: str, additional_description: str = \"\") -> str:\n",
    "    argument = argument_generator(query, additional_description)\n",
    "    criticism = critic(argument)\n",
    "    return refiner(query, additional_description, argument, criticism)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fb9f73",
   "metadata": {
    "id": "97fb9f73"
   },
   "source": [
    "Now call the chain. If you set up your API key correctly at the start of this notebook, all the results should be traced to [Parea](https://www.optimusprompt.ai/dashboard). We will prompt the app to generate an argument that coffee is good for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5798a7",
   "metadata": {
    "tags": [],
    "id": "6f5798a7",
    "outputId": "f4c7b093-561f-493d-c7e2-8cde6352f28c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "result = argument_chain(\n",
    "    \"Whether coffee is good for you.\",\n",
    "    additional_description=\"Provide a concise, few sentence argument on why coffee is good for you.\",\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cad8af8",
   "metadata": {
    "id": "3cad8af8"
   },
   "source": [
    "## Recording feedback\n",
    "\n",
    "The above is all you need to save your app's traces to Parea! You can try changing the functions or raising errors in the above code to see how it's visualized in [Parea](https://www.optimusprompt.ai/dashboard).\n",
    "\n",
    "You can use the trace_id for other things like monitoring user feedback. You can use the get_current_trace_id() helper function to get the trace_id from within the function context.\n",
    "\n",
    "Below, our `argument_chain2` function is identical to the previous one except that we return the trace_id for use outside the function context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117dca62",
   "metadata": {
    "tags": [],
    "id": "117dca62",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from parea.utils.trace_utils import get_current_trace_id\n",
    "\n",
    "\n",
    "@trace\n",
    "def argument_chain2(query: str, additional_description: str = \"\") -> tuple[str, str]:\n",
    "    trace_id = get_current_trace_id()\n",
    "    argument = argument_generator(query, additional_description)\n",
    "    criticism = critic(argument)\n",
    "    return refiner(query, additional_description, argument, criticism), trace_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b339dd8",
   "metadata": {
    "tags": [],
    "id": "2b339dd8"
   },
   "outputs": [],
   "source": [
    "result, trace_id = argument_chain2(\n",
    "    \"Whether coffee is good for you.\",\n",
    "    additional_description=\"Provide a concise, few sentence argument on why coffee is good for you.\",\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167c8ea3",
   "metadata": {
    "id": "167c8ea3"
   },
   "source": [
    "With the trace_id, you can now log feedback from a user after the run is completed. Feedback scores range from 0.0 (bad) to 1.0 (good)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7b378c",
   "metadata": {
    "tags": [],
    "id": "cf7b378c"
   },
   "outputs": [],
   "source": [
    "from parea.schemas.models import FeedbackRequest\n",
    "\n",
    "p.record_feedback(FeedbackRequest(trace_id=trace_id, score=0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1656dd86",
   "metadata": {
    "id": "1656dd86"
   },
   "source": [
    "![Feedback](./img/feedback.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from parea.schemas.models import CompletionResponse\n",
    "\n",
    "\n",
    "# let's return the full CompletionResponse to see what other information is returned\n",
    "def refiner2(query: str, additional_description: str, argument: str, criticism: str) -> CompletionResponse:\n",
    "    return p.completion(\n",
    "        Completion(\n",
    "            deployment_id=\"p-bJ3-UKh9-ixapZafaRBsj\",\n",
    "            llm_inputs={\n",
    "                \"additional_description\": additional_description,\n",
    "                \"date\": f\"{datetime.now()}\",\n",
    "                \"query\": query,\n",
    "                \"argument\": argument,\n",
    "                \"criticism\": criticism,\n",
    "            },\n",
    "        )\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27da340acb87f252"
  },
  {
   "cell_type": "markdown",
   "id": "adfc2fad",
   "metadata": {
    "id": "adfc2fad"
   },
   "source": [
    "## Enriching traces\n",
    "\n",
    "One way to make your application traces more useful or actionable is add tags or metadata to the logs. The trace decorator accepts additional properties such as:\n",
    "\n",
    "- tags: List[str]\n",
    "- metadata: Dict[str, str] - arbitrary key-value metadata\n",
    "- target: str - a gold standard/expected output\n",
    "- end_user_identifier: str - unique identifier for your end user\n",
    "\n",
    "Below is an example. Note: you can also define these properties on the Completion object itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac98115b",
   "metadata": {
    "tags": [],
    "id": "ac98115b",
    "ExecuteTime": {
     "end_time": "2023-08-18T03:35:01.978282Z",
     "start_time": "2023-08-18T03:35:01.900898Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "# you can also add metadata and tags via the decorator\n",
    "@trace(\n",
    "    tags=[\"cookbook-example-deployed\", \"feedback_tracked-deployed\"],\n",
    "    metadata={\"source\": \"python-sdk\", \"deployed\": \"True\"},\n",
    ")\n",
    "def argument_chain_tags_metadata(query: str, additional_description: str = \"\") -> Tuple[CompletionResponse, str]:\n",
    "    trace_id = get_current_trace_id()  # get parent's trace_id\n",
    "    argument = argument_generator(query, additional_description)\n",
    "    criticism = critic(argument)\n",
    "    return refiner2(query, additional_description, argument, criticism), trace_id"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import json, attrs\n",
    "\n",
    "result2, trace_id = argument_chain_tags_metadata(\n",
    "    \"Whether coffee is good for you.\",\n",
    "    additional_description=\"Provide a concise, few sentence argument on why coffee is good for you.\",\n",
    ")\n",
    "print(json.dumps(attrs.asdict(result2), indent=2))\n",
    "\n",
    "p.record_feedback(\n",
    "    FeedbackRequest(\n",
    "        trace_id=trace_id,\n",
    "        score=0.7,  # 0.0 (bad) to 1.0 (good)\n",
    "        target=\"Coffee is wonderful. End of story.\",\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ggpS9JJ-dn4u",
    "outputId": "6a324d73-8b6c-494d-fad3-f0ba0578cc4a"
   },
   "id": "ggpS9JJ-dn4u",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0b955cab",
   "metadata": {
    "id": "0b955cab"
   },
   "source": [
    "Now you can navigate to the detailed logs with the trace_id to see the additional data.\n",
    "\n",
    "![MetaData](./img/meta_data.png)\n",
    "\n",
    "You can see all of your logs on the main dashboard and filter, search, and sort by various criteria.\n",
    "\n",
    "![Dashboard](./img/dashboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d212bffc-9798-43af-8dd7-d3c5fbf72582",
   "metadata": {
    "id": "d212bffc-9798-43af-8dd7-d3c5fbf72582"
   },
   "source": [
    "## Recap\n",
    "You made an example LLM application in this walkthrough and instrumented it using Parea's SDK.\n",
    "\n",
    "You also added tags and metadata and even logged feedback to the logs. The SDK integrates wonderfully with your deployed prompts on Parea, keeping your code flexible and lightweight. Now you can iterate, debug, and monitor your application with ease.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ce1ede35c1909155"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "colab": {
   "provenance": [],
   "toc_visible": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
