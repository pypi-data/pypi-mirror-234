{
	"schema_type": "fault_verifier",
	"schema_version": "1.0.0",
	"faults": [{
		"type": "_cross_validation",
		"result": "done",
		"parameters": [{
			"number_of_folds": "10"
		}],
		"friendly_type": "Cross validation",
		"friendly_result": "In order to accurately evaluate the model(s) trained by AutoML, we leverage a dataset that the model is not trained on. Hence, if the user doesn't provide an explicit validation dataset, a part of the training dataset is used to achieve this. For smaller datasets (fewer than 20,000 samples), cross-validation is leveraged, else a single hold-out set is split from the training data to serve as the validation dataset. Hence, for your input data we leverage cross-validation with 10 folds, if the number of training samples are fewer than 1000, and 3 folds in all other cases.",
		"friendly_parameters": [{
			"Number of folds": "10"
		}],
		"friendly_learn_more": "Learn more about cross validation: https://aka.ms/AutomatedMLCrossValidation",
		"friendly_parameter_preface": ""
	}, {
        "type": "_class_balancing",
		"result": "passed",
		"parameters": [],
		"friendly_type": "Class balancing detection",
		"friendly_result": "Your inputs were analyzed, and all classes are balanced in your training data.",
		"friendly_parameters": [],
		"friendly_learn_more": "Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData",
		"friendly_parameter_preface": "Imbalanced data can lead to a falsely perceived positive effect of a model's accuracy because the input data has bias towards one class."
    }]
}