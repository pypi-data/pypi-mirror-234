Metadata-Version: 2.1
Name: UnBIAS
Version: 2.0.4
Summary: A package for detecting bias, performing named entity, and debiasing text.
Home-page: https://github.com/VectorInstitute/NewsMediaBias/UnBIAS
Author: Shaina Raza
Author-email: shaina.raza@utoronto.ca
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Description-Content-Type: text/markdown
License-File: License.txt
Requires-Dist: pandas
Requires-Dist: transformers
Requires-Dist: torch
Requires-Dist: accelerate
Requires-Dist: peft
Requires-Dist: bitsandbytes
Requires-Dist: trl
Requires-Dist: fire
Requires-Dist: datasets
Requires-Dist: sentencepiece



# UnBIAS - Text Analysis & Debiasing Toolkit

![UnBIAS Logo](https://www.dropbox.com/scl/fi/nfa09b6r2zg4jju3h5hf4/LOGO.png?rlkey=jia62xofhf3204iql1o41r23n&dl=0)


`UnBIAS` is a cutting-edge text analysis and debiasing toolkit that aids in assessing and rectifying biases in textual content. Developed with state-of-the-art Transformer models, this toolkit offers:

## Features

- **Bias Classification**: Evaluate textual content and classify its level of bias.
  
- **Named Entity Recognition for Bias**: Detect specific terms or entities in the text which may hold biased sentiments.

- **Text Debiasing**: Process any text and receive a debiased version in return. This ensures the content is neutral concerning gender, race, age groups, and is free from toxic or harmful language.

**Our models are built on BERT, RobERTa and LLAMA2 7B quantized.**

### Additional Highlights

- **Pre-trained Models**: Uses specialized models from the renowned Hugging Face's Transformers library. These models are especially tailored for bias detection and debiasing tasks.
  
- **Efficient Pipelines**: Designed with intuitive pipelines, making it easier to incorporate into applications or other projects.
  
- **Analytical Tools**: Handy tools available to transform results into structured data for further analysis.

## Installation

To install `UnBIAS`, use pip:

```bash
pip install UnBIAS
```




```python
# Import necessary class/functions from the package
from unbias import BiasPipeline

# Initialize the pipeline
pipeline_instance = BiasPipeline()
texts = ["Women are just too emotional to be leaders.",
        "All young people are lazy and addicted to their phones.",
        "People from that country are always dishonest and corrupt.",
        "You're so stupid; I can't believe you don't get it.",
        "People like you are the reason everything's going wrong.",
        "Why even bother? You'll never amount to anything.",
        "Nobody cares about your pathetic opinion.",
        "You're just a waste of space.",
        "I've met rocks smarter than you.",
        "You're just seeking attention, as always.",
        "Why don't you just shut up for once?",
        "Nobody likes you; we just tolerate you.",
        "You're a disgrace.",
        "All poor people are lazy and don't want to work."
        "People who follow that religion are all terrorists.",
        "Immigrants are taking all our jobs and ruining the country."]
classification_results, ner_results, debiased_texts = pipeline_instance.process(texts)



# Convert results to a DataFrame
df = pipeline_instance.results_to_dataframe(texts, classification_results, ner_results, debiased_texts)

# Save the DataFrame to a CSV file
df.to_csv("debiased_results.csv", index=False)



```

Visit the [documentation](link_to_your_documentation) for more detailed instructions and examples.  <!-- Replace 'link_to_your_documentation' with actual link if you have one -->

## Contribution

If you wish to contribute to this project, please check out the [contribution guidelines](link_to_contribution_guidelines).  <!-- Replace 'link_to_contribution_guidelines' with actual link if you have one -->

## License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.

---

We hope `UnBIAS` proves useful in your journey to make the digital world a more inclusive and unbiased space. For any queries or feedback, feel free to **Shaina Raza** at **shaina.raza@utoronto.ca**.

---

